# Event Driven Architecture avec Apache Kafka et Spring Cloud Streams

[![Java](https://img.shields.io/badge/Java-25-orange.svg)](https://www.oracle.com/java/)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.x-brightgreen.svg)](https://spring.io/projects/spring-boot)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-Latest-black.svg)](https://kafka.apache.org/)

## ğŸ“‹ Description

ActivitÃ© pratique dÃ©montrant l'implÃ©mentation d'une architecture Ã©vÃ©nementielle (Event-Driven Architecture) utilisant **Apache Kafka** et **Spring Cloud Streams**. Cette activitÃ© illustre les concepts de streaming de donnÃ©es en temps rÃ©el, de traitement d'Ã©vÃ©nements et d'analyse de donnÃ©es avec Kafka Streams.

## ğŸ¯ Objectifs du Projet

- Comprendre les fondements de l'architecture Ã©vÃ©nementielle
- MaÃ®triser Apache Kafka (Producer, Consumer, Topics)
- Utiliser Spring Cloud Streams pour l'abstraction de messaging
- ImplÃ©menter du traitement de flux en temps rÃ©el avec Kafka Streams
- Visualiser des analytics en temps rÃ©el dans une interface web

## ğŸ—ï¸ Architecture
![Architecture](assets/1-Architecture.svg)

## ğŸš€ Technologies UtilisÃ©es

- **Java 25**
- **Spring Boot 3.x**
- **Spring Cloud Streams** - Abstraction pour le messaging
- **Apache Kafka** - Plateforme de streaming distribuÃ©
- **Kafka Streams** - BibliothÃ¨que de traitement de flux
- **Docker & Docker Compose** - Conteneurisation
- **Chart.js** - Visualisation des donnÃ©es

## ğŸ“¦ PrÃ©requis

- Java JDK 25 ou supÃ©rieur
- Docker Desktop installÃ© et dÃ©marrÃ©
- IntelliJ IDEA (recommandÃ©) ou tout autre IDE Java
- Maven (intÃ©grÃ© avec IntelliJ)

## ğŸ”§ Installation et DÃ©marrage

### 1. Cloner le repository

```bash
git clone https://github.com/jaouad4/kafka-spring-cloud-stream
cd kafka-spring-cloud-stream
```

### 2. DÃ©marrer Kafka et Zookeeper avec Docker

```bash
docker-compose up -d
```
![docker-compose up -d](assets/2-Docker_compose_command.png)
![docker-compose up -d results](assets/2.5-Docker_compose_results.png)
VÃ©rifier que les conteneurs sont actifs :
```bash
docker ps
```
![docker ps](assets/3-Docker_ps.png)
![docker ps result 1](assets/3.5.1-Docker_ps_result1.png)
![docker ps result 2](assets/3.5.2-Docker_ps_result2.png)

### 3. DÃ©marrer l'application Spring Boot

Avec Maven :
```bash
mvn spring-boot:run
```

Ou depuis IntelliJ : *Run â†’ Run 'Application'*

<!-- [Screenshot : IntelliJ IDEA avec l'application dÃ©marrÃ©e, console montrant "Started KafkaSpringCloudStreamApplication"] -->

### 4. Tester l'application

L'application sera disponible sur `http://localhost:8080`

## ğŸ“ FonctionnalitÃ©s ImplÃ©mentÃ©es

### 1. Producer REST (Topic T2)

Envoyer un Ã©vÃ©nement via HTTP :
```
GET http://localhost:8080/publish?name=P1&topic=T2
```

**ParamÃ¨tres :**
- `name` : Nom de la page (P1, P2, etc.)
- `topic` : Topic Kafka de destination
<!-- [Screenshot : Navigateur web avec l'URL http://localhost:8080/publish?name=P1&topic=T2 et la rÃ©ponse JSON affichÃ©e] -->

<!-- [Screenshot : Postman ou navigateur montrant la requÃªte et la rÃ©ponse avec les dÃ©tails de PageEvent] -->

### 2. Consumer Kafka

Consomme automatiquement les messages du topic T2 et les affiche dans la console.

<!-- [Screenshot : Console IntelliJ montrant les logs du Consumer avec les Ã©toiles et les messages PageEvent reÃ§us] -->

**Exemple de sortie console :**
```
Consuming: PageEvent[name=P1, user=U2, date=Sun Oct 05 18:30:45 CET 2025, duration=1567]
```

### 3. Supplier (Auto-Producer vers T3)

GÃ©nÃ¨re automatiquement des Ã©vÃ©nements PageEvent toutes les 200ms vers le topic T3.

**Configuration dans `application.properties` :**
```properties
spring.cloud.stream.bindings.pageEventSupplier-out-0.producer.poller.fixed-delay=200
```

<!-- [Screenshot : Fichier application.properties ouvert dans IntelliJ avec les configurations en surbrillance] -->

### 4. Kafka Streams - Analytics en Temps RÃ©el

Traite le flux d'Ã©vÃ©nements du topic T3 :
- **Filtrage** : DurÃ©e de visite > 100ms
- **Groupement** : Par nom de page (P1, P2)
- **FenÃªtrage** : FenÃªtre glissante de 5 secondes
- **AgrÃ©gation** : Comptage du nombre de visites
- **Output** : RÃ©sultats publiÃ©s sur topic T4

<!-- [Screenshot : Code source de la fonction kstreamFunction dans IntelliJ] -->

### 5. Interface Web de Visualisation

AccÃ©der Ã  : `http://localhost:8080/index.html`

Affiche en temps rÃ©el :
- Graphique Ã  barres du nombre de visites par page
- Mise Ã  jour toutes les secondes

<!-- [Screenshot : Page web avec le graphique Chart.js montrant les barres P1 et P2 avec des valeurs] -->

<!-- [Screenshot : Animation ou GIF montrant le graphique se mettre Ã  jour en temps rÃ©el] -->

## ğŸ§ª Tests avec Kafka Console

### Tester le Producer Console

```bash
docker exec -it bdcc-kafka-broker kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic T1
```

<!-- [Screenshot : Terminal avec kafka-console-producer actif, prÃªt Ã  recevoir des messages] -->

### Tester le Consumer Console

```bash
docker exec -it bdcc-kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic T1 \
  --from-beginning
```

<!-- [Screenshot : Deux terminaux cÃ´te Ã  cÃ´te - Producer Ã  gauche envoyant "Hello", Consumer Ã  droite recevant "Hello"] -->

### Consommer les messages du Topic T2

```bash
docker exec -it bdcc-kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic T2
```

<!-- [Screenshot : Terminal montrant les messages JSON PageEvent reÃ§us sur le topic T2] -->

### Consommer les messages du Topic T3 (Supplier)

```bash
docker exec -it bdcc-kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic T3
```

<!-- [Screenshot : Terminal montrant le flux continu de messages gÃ©nÃ©rÃ©s automatiquement toutes les 200ms] -->

### Visualiser les rÃ©sultats Kafka Streams (T4)

```bash
docker exec -it bdcc-kafka-broker kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic T4 \
  --property print.key=true \
  --property print.value=true \
  --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \
  --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer
```

<!-- [Screenshot : Terminal montrant les rÃ©sultats du Kafka Streams avec format "P1	150" et "P2	120"] -->

**Exemple de sortie :**
```
P1	145
P2	138
P1	150
P2	142
```

## ğŸ“Š Structure du Projet

```
kafka-spring-cloud-stream/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â”‚   â””â”€â”€ ma/youssfi/
â”‚   â”‚   â”‚       â”œâ”€â”€ KafkaSpringCloudStreamApplication.java
â”‚   â”‚   â”‚       â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ PageEventController.java
â”‚   â”‚   â”‚       â”œâ”€â”€ events/
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ PageEvent.java
â”‚   â”‚   â”‚       â””â”€â”€ handlers/
â”‚   â”‚   â”‚           â””â”€â”€ PageEventHandler.java
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â”œâ”€â”€ application.properties
â”‚   â”‚       â””â”€â”€ static/
â”‚   â”‚           â””â”€â”€ index.html
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

<!-- [Screenshot : Explorateur de fichiers IntelliJ montrant l'arborescence complÃ¨te du projet] -->

## ğŸ” Concepts ClÃ©s

### PageEvent

Record Java reprÃ©sentant un Ã©vÃ©nement de visite de page :
```java
public record PageEvent(
    String name,      // Nom de la page (P1, P2)
    String user,      // Utilisateur (U1, U2)
    Date date,        // Date de la visite
    long duration     // DurÃ©e de visite en ms
) {}
```

<!-- [Screenshot : Code source de PageEvent.java dans IntelliJ] -->

### Spring Cloud Stream Bindings

- **Consumer** : `<functionName>-in-<index>`
- **Producer/Supplier** : `<functionName>-out-<index>`
- **Function** : Input et Output dÃ©finis

### Kafka Streams Operations

- **filter()** : Filtrer les Ã©vÃ©nements selon une condition
- **map()** : Transformer les Ã©vÃ©nements
- **groupByKey()** : Grouper par clÃ©
- **windowedBy()** : DÃ©finir une fenÃªtre temporelle
- **count()** : Compter les Ã©vÃ©nements dans chaque groupe/fenÃªtre

<!-- [Screenshot : Code annotÃ© montrant chaque opÃ©ration Kafka Streams avec des commentaires] -->

## ğŸ“ˆ DÃ©monstration ComplÃ¨te

### ScÃ©nario de Test Complet

1. **DÃ©marrage des services**

<!-- [Screenshot : Docker Desktop avec tous les conteneurs dÃ©marrÃ©s] -->

2. **Publication d'Ã©vÃ©nements via REST**

<!-- [Screenshot : Multiples onglets de navigateur envoyant des requÃªtes publish] -->

3. **Consommation en temps rÃ©el**

<!-- [Screenshot : 3 terminaux affichant simultanÃ©ment T2, T3 et T4] -->

4. **Visualisation Web**

<!-- [Screenshot : Page web finale avec le graphique animÃ© montrant les statistiques en temps rÃ©el] -->

## ğŸ› Troubleshooting

### Docker ne dÃ©marre pas
```bash
# VÃ©rifier que Docker Desktop est lancÃ©
docker info

# RedÃ©marrer les conteneurs
docker-compose down
docker-compose up -d
```

<!-- [Screenshot : Docker Desktop Settings ou message d'erreur rÃ©solu] -->

### Port 9092 dÃ©jÃ  utilisÃ©
Modifiez le port dans `docker-compose.yml` et `application.properties`.

<!-- [Screenshot : Modification du fichier docker-compose.yml avec le nouveau port] -->

### Les messages n'arrivent pas
VÃ©rifiez que les topics et bindings correspondent dans la configuration.

<!-- [Screenshot : Fichier application.properties avec les bindings en surbrillance] -->

### Erreur au dÃ©marrage de l'application
```bash
# Nettoyer et recompiler
mvn clean install
```

<!-- [Screenshot : Console Maven montrant "BUILD SUCCESS"] -->

## ğŸ“š Ressources

- [VidÃ©o du cours - Prof. Mohamed YOUSSFI](https://www.youtube.com/watch?v=8uY7JE_X_Fw)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Spring Cloud Stream](https://spring.io/projects/spring-cloud-stream)
- [Kafka Streams Documentation](https://kafka.apache.org/documentation/streams/)

## ğŸ¥ VidÃ©o de DÃ©monstration

<!-- [Screenshot ou lien : VidÃ©o de dÃ©monstration du projet en action (si vous en crÃ©ez une)] -->

## ğŸ“¸ Galerie

### Configuration et Setup

<!-- [Screenshot : docker-compose.yml ouvert dans l'Ã©diteur] -->

<!-- [Screenshot : pom.xml montrant les dÃ©pendances Spring Cloud Stream et Kafka] -->

### Code Principal

<!-- [Screenshot : PageEventController.java - mÃ©thode publish()] -->

<!-- [Screenshot : PageEventHandler.java - les trois beans (Consumer, Supplier, Function)] -->

### RÃ©sultats et Logs

<!-- [Screenshot : Console complÃ¨te montrant tous les logs lors de l'exÃ©cution] -->

<!-- [Screenshot : Kafka console consumer avec un flux de donnÃ©es] -->

### Interface Utilisateur

<!-- [Screenshot : Code HTML/JavaScript de index.html] -->

<!-- [Screenshot : Inspecteur de navigateur montrant les requÃªtes en temps rÃ©el] -->

## ğŸ‘¨â€ğŸ“ Auteur

**Votre Nom**  
ActivitÃ© Pratique NÂ°1 - Event Driven Architecture  
Professeur : Mohamed YOUSSFI  
Date : Octobre 2025

<!-- [Screenshot : Photo de profil ou avatar (optionnel)] -->

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans un cadre acadÃ©mique.

---

## âœ… Checklist de Validation

- [x] Docker Desktop installÃ© et dÃ©marrÃ©
- [x] Kafka et Zookeeper lancÃ©s avec `docker-compose up -d`
- [x] Application Spring Boot dÃ©marre sans erreur
- [x] Test du REST Producer fonctionnel
- [x] Consumer affiche les messages dans la console
- [x] Supplier gÃ©nÃ¨re des Ã©vÃ©nements automatiquement
- [x] Kafka Streams traite et compte les Ã©vÃ©nements
- [x] Interface web accessible et affiche les graphiques
- [x] Tous les fichiers commitÃ©s sur GitHub
- [x] README.md complet et formatÃ©
- [x] Screenshots ajoutÃ©s dans le README

<!-- [Screenshot : Repository GitHub montrant tous les fichiers commitÃ©s avec un beau README] -->

---

â­ Si ce projet vous a Ã©tÃ© utile, n'oubliez pas de mettre une Ã©toile !

<!-- [Screenshot : Page GitHub du projet avec le bouton Star en Ã©vidence] -->
